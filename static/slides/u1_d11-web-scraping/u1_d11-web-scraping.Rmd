---
title: "Web scraping <br> `r emo::ji('spider_web')`"
author: ""
output:
  xaringan::moon_reader:
    css: "../slides.css"
    lib_dir: libs
    nature:
      highlightLines: true
      highlightStyle: solarized-dark
      countIncrementalSlides: false
      mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
---

```{r child = "../setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
library(knitr)
```

class: center, middle

# Scraping the web

---

## Scraping the web: what? why?

- Increasing amount of data is available on the web
--

- These data are provided in an unstructured format: you can always copy&paste, 
but it's time-consuming and prone to errors

--
- Web scraping is the process of extracting this information automatically and transform it into a structured dataset

--
- Two different scenarios:
    - Screen scraping: extract data from source code of website, with html 
    parser (easy) or regular expression matching (less easy).
    - Web APIs (application programming interface): website offers a set of 
    structured http requests that return JSON or XML files.

---

class: center, middle

# Web Scraping with rvest

---

## Hypertext Markup Language

- Most of the data on the web is still largely available as HTML 
- It is structured (hierarchical / tree based), but it''s often not available in 
a form useful for analysis (flat / tidy).

```html
<html>
  <head>
    <title>This is a title</title>
  </head>
  <body>
    <p align="center">Hello world!</p>
  </body>
</html>
```

---

## rvest

.pull-left[
- The **rvest** package makes basic processing and manipulation of HTML data straight forward
- It's designed to work with pipelines built with `%>%`
]
.pull-right[
```{r echo=FALSE,out.width=230,fig.align="right"}
knitr::include_graphics("img/rvest.png")
```
]

---

## Core rvest functions

- `read_html`   - Read HTML data from a url or character string
- `html_node `  - Select a specified node from HTML document
- `html_nodes`  - Select specified nodes from HTML document
- `html_table`  - Parse an HTML table into a data frame
- `html_text`   - Extract tag pairs' content
- `html_name`   - Extract tags' names
- `html_attrs`  - Extract all of each tag's attributes
- `html_attr`   - Extract tags' attribute value by name

---

## SelectorGadget

.pull-left[
- Open source tool that eases CSS selector generation and discovery
- Easiest to use with the [Chrome Extension](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb) 
- Find out more on the [SelectorGadget vignette](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html)
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics("img/selector-gadget.png")
```
]

---

## Using the SelectorGadget

.pull-left[
- Click on the app logo next to the search bar
- A box will open in the bottom right of the website
]
.pull-right[
```{r echo=FALSE,fig.align="center",out.height=250}
knitr::include_graphics("img/selector-gadget.gif")
```
]

--

- Click on a page element (it will turn green), SelectorGadget will generate a 
minimal CSS selector for that element, and will highlight (yellow) everything 
that is matched by the selector

--
- Click on a highlighted element to remove it from the selector (red), or 
click on an unhighlighted element to add it to the selector

--
- Through this process of selection and rejection, SelectorGadget helps you come 
up with the appropriate CSS selector for your needs


---

class: center, middle

# Top 250 movies on IMDB

---

## Top 250 movies on IMDB

Take a look at the source code, look for the tag `table` tag:
<br>
http://www.imdb.com/chart/top

![imdb_top](img/imdb_top_250.png)

---

## First check if you're allowed!

```{r warning=FALSE}
library(robotstxt)
paths_allowed("http://www.imdb.com")
```

vs. e.g.

```{r warning=FALSE}
paths_allowed("http://www.facebook.com")
```


---

## Demo

```{r echo=FALSE, fig.align="center", out.height=200, out.width=320}
knitr::include_graphics("img/demo.png")
```

<br><br>

.center[
Go to [rstudio.cloud](https://rstudio.cloud/spaces/3518/projects)  
Make a copy of the project titled *Demo - Web scraping*  
Open `scrape-250.R`
]

---

## Select and format pieces

.midi[
```{r message=FALSE}
page <- read_html("http://www.imdb.com/chart/top")

titles <- page %>%
  html_nodes(".titleColumn a") %>%
  html_text()

years <- page %>%
  html_nodes(".secondaryInfo") %>%
  html_text() %>%
  str_replace("\\(", "") %>% # remove (
  str_replace("\\)", "") %>% # remove )
  as.numeric()

scores <- page %>%
  html_nodes("#main strong") %>%
  html_text() %>%
  as.numeric()
  
imdb_top_250 <- tibble(
  title = titles, 
  year = years, 
  score = scores
  )
```
]

---

```{r echo=FALSE, results='asis'}
imdb_top_250 %>% head(15)%>% rbind(rep("...", 3)) %>% kable(format = "html")
```

---

## Clean up / enhance

May or may not be a lot of work depending on how messy the data are

- See if you like what you got:

```{r}
glimpse(imdb_top_250)
```

- Add a variable for rank
```{r}
imdb_top_250 <- imdb_top_250 %>%
  mutate(
    rank = 1:nrow(imdb_top_250)
  )
```

---

```{r echo=FALSE, results='asis'}
imdb_top_250 %>% head(15)%>% rbind(rep("...", 3)) %>% kable(format = "html")
```

---

## Analyze

.question[
How would you go about answering this question: Which 1995 movies made the list?
]

--

```{r}
imdb_top_250 %>% 
  filter(year == 1995)
```

---

## Analyze

.question[
How would you go about answering this question: Which years have the most movies on the list?
]

--

```{r}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(total = n()) %>%
  arrange(desc(total)) %>%
  head(5)
```

---

## Visualize

.question[
How would you go about creating this visualization: Visualize the average yearly score for movies that made it on the top 250 list over time.
]

--

.small[
```{r echo=FALSE}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(avg_score = mean(score)) %>%
  ggplot(aes(y = avg_score, x = year)) +
    geom_point() +
    geom_smooth(method = "lm") +
    xlab("year")
```
]
---

## Potential challenges

- Unreliable formatting at the source
- Data broken into many pages
- ...

.question[
Compare the display of information at [raleigh.craigslist.org/search/apa](https://raleigh.craigslist.org/search/apa) to the list on the IMDB top 250 list. What challenges can you foresee in scraping a list of the available apartments?
]

---

class: center, middle

# Application exercise

---

## <i class="fas fa-laptop"></i> AE 07 - Web scraping

- Clone your assignment repo in RStudio Cloud (`ae-07-web-scraping-TEAMNAME`)
- Open the R script called `scrape-tvshows.R`
- Scrape the names, scores, and years of most popular TV shows on IMDB:
[www.imdb.com/chart/tvmeter](http://www.imdb.com/chart/tvmeter)
- Create a data frame called `tvshows` with four variables 
(`rank`, `name`, `score`, `year`)  
- Examine each of the **first three** TV shows to also obtain 
  - Genre
  - Runtime
  - How many episodes so far
  - First five plot keywords
- Add this information to the `tvshows` data frame you created earlier

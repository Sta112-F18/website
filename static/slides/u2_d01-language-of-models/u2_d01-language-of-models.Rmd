---
title: "The language of models <br> `r emo::ji('chart_with_upwards_trend')`"
author: ""
output:
  xaringan::moon_reader:
    css: "../slides.css"
    lib_dir: libs
    nature:
      highlightLines: true
      highlightStyle: solarized-dark
      countIncrementalSlides: false
      mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
---

```{r setup, child = "../setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
library(knitr)
library(broom)
library(DT)
```

## Announcements

- HW 6 due Tuesday
- New teams:
  - team 1: tyee, akshara, florence, yuncong
  - team 2: andres, liz, aaron, margaret
  - team 3: yi, ben, natalie, ritik
  - team 4: evdards, jackson, dora, justin
- Dr. Cetinkaya-Rundel available on Slack for questions + Eidan has OH Friday and Monday

---

class: center, middle

# The language of models

---

## Modelling

- Use models to explain the relationship between variables and to make predictions
- For now we will focus on **linear** models (but remember there are *many* *many* other types of models too!)

---
class: center, middle

# Data: Paris Paintings

---

## Paris Paintings

```{r load-pp, message=FALSE}
pp <- read_csv(
  "data/paris_paintings.csv", 
  na = c("n/a", "", "NA")
)
```

.question[
What does the `data/` mean in the code above? Hint: Where is the data file located?
]

---

## Meet the data curators

.center[
![](img/sandra-van-ginhoven.png) ![](img/hilary-coe-cronheim.png)

Sandra van Ginhoven &nbsp; &nbsp; Hilary Coe Cronheim

PhD students in the Duke Art, Law, and Markets Initiative in 2013
]

- Source: Printed catalogues of 28 auction sales in Paris, 1764- 1780
- 3,393 paintings, their prices, and descriptive details from sales catalogues over 60 variables

---

## Auctions today

![](img/auction-video.png)

.tiny[
http://www.sothebys.com/en/news-video/videos/2014/07/Old-master-british-paintings-evening-sale-soars-over-estimate.html
]

---

## Auctions back in the day

![](img/old-auction.png)

Pierre-Antoine de Machy, Public Sale at the Hôtel Bullion, Musée Carnavalet, Paris (18th century)

---

## Paris auction market

![](img/auction-trend-paris.png)

---

## Depart pour la chasse

![](img/depart-pour-la-chasse.png)

---

## Auction catalog text

.pull-left[
![](img/auction-catalogue.png)

]
.pull-right[
.small[
Two paintings very rich in composition, of a beautiful execution, and whose merit is very remarkable, each 17 inches 3 lines high, 23 inches wide; the first, painted on wood, comes from the Cabinet of Madame la Comtesse de Verrue; it represents a departure for the hunt: it shows in the front a child on a white horse, a man who gives the horn to gather the dogs, a falconer and other figures nicely distributed across the width of the painting; two horses drinking from a fountain; on the right in the corner a lovely country house topped by a terrace, on which people are at the table, others who play instruments; trees and fabriques pleasantly enrich the background.
]
]

---

![](img/painting1.png)
![](img/painting2.png)
![](img/painting3.png)

---

```{r glimpse-obs}
pp %>% 
  filter(name == "R1777-89a") %>% 
  select(name:endbuyer) %>% 
  glimpse()
```

---

class: center, middle

# Modelling the relationship between variables

---

## Heights

.question[
Describe the distribution of heights of paintings.
]

```{r height-dist, fig.height=2.3}
ggplot(data = pp, aes(x = Height_in)) +
  geom_histogram(bins = 30)
```

---

## Widths

.question[
Describe the distribution of widths of paintings.
]

```{r width-dist, fig.height=2.3}
ggplot(data = pp, aes(x = Width_in)) +
  geom_histogram(bins = 30)
```

---

## Models as functions

- We can represent relationships between variables using **functions**
- A function is a mathematical concept: the relationship between an output
and one or more inputs. 
    - Plug in the inputs and receive back the output
    - Example: the formula $y = 3x + 7$ is a function with input $x$ and output $y$,
    when $x$ is $5$, the output $y$ is $22$
    ```
    y = 3 * 5 + 7 = 22
    ```

---

## Height as a function of width

.question[
Describe the relationship between height and width of paintings.
]

```{r height-width-plot, warning = FALSE, echo=FALSE}
ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm") # lm for linear model
```

---

## Visualizing the linear model

```{r height-width-plot-code, warning = FALSE}
ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm") # lm for linear model
```

---

## Visualizing the linear model

... without the measure of uncertainty around the line

```{r height-width-plot-no-se, warning = FALSE, fig.height=2.25, fig.width=5}
ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

---

## Visualizing the linear model

... with different cosmetic choices for the line

```{r height-width-plot-pink-line, warning = FALSE, fig.height=2.25, fig.width=5}
ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, 
              # color       # line type # line weight
              col = "pink", lty = 2,    lwd = 3)
```

---

## Vocabulary

- **Response variable:** Variable whose behavior or variation you are trying to 
understand, on the y-axis (dependent variable)
- **Explanatory variables:** Other variables that you want to use to explain the 
variation in the response, on the x-axis (independent variables)
- **Predicted value:** Output of the **model function**
    - The model function gives the typical (expected) value of the response 
    variable *conditioning* on the explanatory variables
- **Residuals:** A measure of how far each case is from its predicted value 
(based on a particular model)
    - Residual = Observed value - Predicted value
    - Tells how far above/below the expected value each case is

---

## Residuals

.question[
What does a negative residual mean? Which paintings on the plot have have 
negative residuals, those below or above the line?
]

```{r height-width-plot-no-se2, warning = FALSE, echo=FALSE}
ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

---

.question[
The plot below displays the relationship between height and width of paintings. The only difference from the previous plot is that it uses a smaller alpha value, making the points somewhat transparent. 

What feature is apparent in this plot that was not (as) apparent in the previous plots? What might be the reason for this feature?
]

```{r height-width-plot-alpha, warning = FALSE, echo=FALSE}
ggplot(data = pp, aes(x = Width_in, y = Height_in)) +
  geom_point(alpha = 0.2)
```

---

## Landscape paintings

- Landscape painting is the depiction in art of landscapes – natural scenery 
such as mountains, valleys, trees, rivers, and forests, especially where the 
main subject is a wide view – with its elements arranged into a coherent
composition.<sup>1</sup>
    - Landscape paintings tend to be wider than they are long.
- Portrait painting is a genre in painting, where the intent is to depict a 
human subject.<sup>2</sup>
    - Portrait paintings tend to be longer than they are wide.

.footnote[
[1] Source: Wikipedia, [Landscape painting](https://en.wikipedia.org/wiki/Landscape_painting)

[2] Source: Wikipedia, [Portait painting](https://en.wikipedia.org/wiki/Portrait_painting)
]

---

## Multiple explanatory variables

.question[
How, if at all, the relatonship between width and height of paintings vary by 
whether or not they have any landscape elements?
]
.small[
```{r height-width-landscape, warning = FALSE, fig.height=2}
ggplot(data = pp, aes(x = Width_in, y = Height_in, 
                      color = factor(landsALL))) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(color = "landscape")
```
]
---

## Extending Regession lines

.small[
```{r extrapolation, warning = FALSE, fig.height=2}
ggplot(data = pp, aes(x = Width_in, y = Height_in, 
                      color = factor(landsALL))) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  labs(color = "landscape")
```
]
---

## Models - upsides and downsides

- Models can sometimes reveal patterns that are not evident in a graph of the
data. This is a great advantage of modelling over simple visual inspection of
data. 
- There is a real risk, however, that a model is imposing structure that is
not really there on the scatter of data, just as people imagine animal shapes in
the stars. A skeptical approach is always warranted.

---

## Variation around the model...

is just as important as the model, if not more!  

*Statistics is the explanation of variation in the context of what remains
unexplained.*

- The scatter suggests that there might be other factors that account for large 
parts of painting-to-painting variability, or perhaps just that randomness plays 
a big role.
- Adding more explanatory variables to a model can sometimes usefully reduce
the size of the scatter around the model. (We'll talk more about this later.)

---

## How do we use models?

- Explanation: Characterize the relationship between $y$ and $x$ via *slopes* 
for numerical explanatory variables or *differences* for categorical explanatory 
variables
- Prediction: Plug in $x$, get the predicted $y$

---

class: center, middle

# Interpreting models

---

## Height & width

```{r}
m_ht_wt <- lm(Height_in ~ Width_in, data = pp)
tidy(m_ht_wt)
```

--

$$\widehat{Height_{in}} = 3.62 + 0.78~Width_{in}$$

--

- **Slope:** For each additional inch the painting is wider, the height is 
expected to be higher, on average, by 0.78 inches.

--
- **Intercept:** Paintings that are 0 inches wide are expected to be 3.62 
inches high, on average.
    - Does this make sense?

---

## broom $\in$ tidyverse

.pull-left[
![](img/broom-part-of-tidyverse.png)
]
.pull-right[
- **broom** follows tidyverse principles and tidies up regression output
- `tidy`: Constructs a tidy data frame summarizing model's statistical findings
- `glance`: Constructs a concise one-row summary of the model
- `augment`: Adds columns (e.g. predictions, residuals) to the original data that was modeled
]

.footnote[
[broom.tidyverse.org](https://broom.tidyverse.org)
]

---

## Linear model with a single predictor

- We're interested in $\beta_0$ (population parameter for the intercept) and 
$\beta_1$ (population parameter for the slope) in the following model:

$$ \hat{y} = \beta_0 + \beta_1~x $$

--
- Tough luck, you can't have them...

--
- So we use sample statistics to estimate them:

$$ \hat{y} = b_0 + b_1~x $$

---

## Least squares regression

- The regression line minimizes the sum of squared residuals.

--
- If $e_i = y - \hat{y}$, then, the regression line minimizes 
$\sum_{i = 1}^n e_i^2$.

---

## Visualizing residuals

```{r vis-res-1, fig.height=3.5, echo=FALSE}
d <- tibble(
    Width_in     = m_ht_wt$model$Width_in,
    Height_in    = m_ht_wt$model$Height_in,
    pred         = m_ht_wt$fitted.values,
    res          = m_ht_wt$residuals
  )
p <- ggplot(data = d, mapping = aes(x = Width_in, y = Height_in)) +
  geom_point(alpha = 0.2) + 
  theme_bw() +
  labs(title = "Height vs. width of paintings", subtitle = "Just the data") +
  xlim(0, 250) +
  ylim(0, 200)
p
```

---

## Visualizing residuals (cont.)

```{r vis-res-2, fig.height=3.5, echo=FALSE}
p <- p + 
  geom_smooth(method = "lm", color = "#A7D5E8", se = FALSE) +
  geom_point(mapping = aes(y = pred), color = "#1E5C65") +
  labs(subtitle = "Data + least squares resgression line")
p
```

---

## Visualizing residuals (cont.)

```{r vis-res-3, fig.height=3.5, echo = FALSE}
p + 
  geom_segment(mapping = aes(xend = Width_in, yend = pred), 
               color = "#A7D5E8", alpha = 0.4) +
  labs(subtitle = "Data + least squares resgression line + residuals")
```


---

## Properties of the least squares regression line

- The regression line goes through the center of mass point, the coordinates corresponding to average $x$ and average $y$: $(\bar{x}, \bar{y})$:  
$$\hat{y} = b_0 + b_1 x ~ \rightarrow ~ b_0 = \hat{y} - b_1 x$$
- The slope has the same sign as the correlation coefficient:  
$$b_1 = r \frac{s_y}{s_x}$$
- The sum of the residuals is zero:  
$$\sum_{i = 1}^n e_i = 0$$
- The residuals and $x$ values are uncorrelated.

---

## Height & landscape features

```{r}
m_ht_lands <- lm(Height_in ~ factor(landsALL), data = pp)
tidy(m_ht_lands)
```

--

$$\widehat{Height_{in}} = 22.68 - 5.65~landsALL$$

---

## Height & landscape features (cont.)

- **Slope:** Paintings with landscape features are expected, on average,
to be 5.65 inches shorter than paintings that without landscape features.
    - Compares baseline level (`landsALL = 0`) to other level
    (`landsALL = 1`).
- **Intercept:** Paintings that don't have landscape features are expected, on 
average, to be 22.68 inches tall.

---

## Categorical predictor with 2 levels

```{r echo=FALSE}
pp %>% 
  select(name, price, landsALL) %>% 
  slice(1:8)
```

---

## Relationship between height and school

```{r}
m_ht_sch <- lm(Height_in ~ school_pntg, data = pp)
tidy(m_ht_sch)
```

--
- When the categorical explanatory variable has many levels, they're encoded to
**dummy variables**.
- Each coefficient describes the expected difference between heights in that 
particular school compared to the baseline level.

---

## Categorical predictor with >2 levels

```{r echo=FALSE}
pp %>% 
  select(school_pntg) %>% 
  group_by(school_pntg) %>% 
  sample_n(1) %>%
  mutate(
    D_FL = as.integer(ifelse(school_pntg == "D/FL", 1L, 0)),
    F    = as.integer(ifelse(school_pntg == "F", 1L, 0)),
    G    = as.integer(ifelse(school_pntg == "G", 1L, 0)),
    I    = as.integer(ifelse(school_pntg == "I", 1L, 0)),
    S    = as.integer(ifelse(school_pntg == "S", 1L, 0)),
    X    = as.integer(ifelse(school_pntg == "X", 1L, 0))
  )
```

---

## The linear model with multiple predictors

- Population model:

$$ \hat{y} = \beta_0 + \beta_1~x_1 + \beta_2~x_2 + \cdots + \beta_k~x_k $$

--

- Sample model that we use to estimate the population model:
  
$$ \hat{y} = b_0 + b_1~x_1 + b_2~x_2 + \cdots + b_k~x_k $$

---

## Correlation does not imply causation!

Remember this when interpreting model coefficients

![](img/cell_phones.png)

.footnote[
Source: XKCD, [Cell phones](https://xkcd.com/925/)
]